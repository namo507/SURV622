---
title: "Assignment 1: Namit Shrivastava"
format: pdf
editor: visual
---

Firstly, I will be installing and loading the RecordLinkage package
```{r warning=FALSE, message=FALSE}
if (!requireNamespace("RecordLinkage", quietly = TRUE)) {
  install.packages('RecordLinkage')
}
library('RecordLinkage', quietly=TRUE)
```

Now given the two csv files, I will be loading and cleaning the data.

```{r}
# Importing datasets
sdfilepath = "surveydata.csv"
adfilepath = "admindata.csv"

# Reading the data
surveydata <- read.csv(sdfilepath, header=TRUE, sep=",", stringsAsFactors = FALSE)
admindata <- read.csv(adfilepath, header=TRUE, sep=",", stringsAsFactors = FALSE)

# Cleaning column names
colnames(surveydata) <- c("matchid","dup","firstname","lastname","maritalstatus",
                         "race","dob","ssn","income","credit_card_num","city",
                         "zip","telephone")
colnames(admindata) <- c("matchid","dup","firstname","lastname","maritalstatus",
                        "race","dob","ssn","income","credit_card_num","city",
                        "zip","telephone")

# Removing empty rows
surveydata <- surveydata[complete.cases(surveydata[,1:2]), ]
admindata <- admindata[complete.cases(admindata[,1:2]), ]

# Creating derived columns
# 1. Full name (first initial + last name)
surveydata$fullname <- paste(substring(surveydata$firstname,1,1), 
                           surveydata$lastname, sep='')
admindata$fullname <- paste(substring(admindata$firstname,1,1), 
                          admindata$lastname, sep='')

# 2. Processing dates
surveydata$dob <- as.Date(surveydata$dob, format="%m/%d/%Y")
admindata$dob <- as.Date(admindata$dob, format="%m/%d/%Y")

# 3. Extracting date components
surveydata$month <- as.numeric(format(surveydata$dob, "%m"))
surveydata$day <- as.numeric(format(surveydata$dob, "%d"))
surveydata$year <- as.numeric(format(surveydata$dob, "%Y"))
admindata$month <- as.numeric(format(admindata$dob, "%m"))
admindata$day <- as.numeric(format(admindata$dob, "%d"))
admindata$year <- as.numeric(format(admindata$dob, "%Y"))

# 4. First three letters of lastname
surveydata$lastthree <- substring(surveydata$lastname,1,3)
admindata$lastthree <- substring(admindata$lastname,1,3)

# Creating identity vectors
identity_survey <- surveydata$matchid
identity_admin <- admindata$matchid

# Verify the data
cat("Data dimensions:\n")
cat("Survey data:", dim(surveydata), "\n")
cat("Admin data:", dim(admindata), "\n")

# Check for NA values in key fields
cat("\nMissing values in key fields:\n")
cat("Survey DOB NAs:", sum(is.na(surveydata$dob)), "\n")
cat("Admin DOB NAs:", sum(is.na(admindata$dob)), "\n")
```

Now let me analyse and explain the data in layman terms.

So I have 2 datasets, a survey dataset with 3,000 records and a larger administrative dataset with 13,551 records. Both datasets now have 18 columns each, which includes our original fields plus the new ones that I created (like the full name combining first initial and last name, and the separated date components).

What's interesting, and potentially concerning, is that I have some missing dates of birth: 11 missing in the survey data and 49 missing in the administrative data. This could impact my matching process since date of birth is often a key field for linking records. I will need to keep this in mind when I move forward with record linkage, as these records might be harder to match confidently.


## Approach 1: Exact Matching (No Blocking)
```{r}
# 1. Using Jarowinkler
exact_jarowinkler <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = NULL,
  strcmp = TRUE,
  strcmpfun = "jarowinkler",
  exclude = c(1:2, 5:13, 15:18)
)
exact_jarowinkler_w <- emWeights(exact_jarowinkler, cutoff = 0.95)
exact_jarowinkler_class <- emClassify(exact_jarowinkler_w, threshold.upper = 0)
```
```{r}
# 2. Using Levenshtein
exact_levenshtein <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = NULL,
  strcmp = TRUE,
  strcmpfun = "levenshtein",
  exclude = c(1:2, 5:13, 15:18)
)
exact_levenshtein_w <- emWeights(exact_levenshtein, cutoff = 0.95)
exact_levenshtein_class <- emClassify(exact_levenshtein_w, threshold.upper = 0)
```
```{r}
# 3. Using Phonetic Matching (Soundex)
exact_phonetic <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = NULL,
  phonetic = TRUE,
  exclude = c(1:2, 5:13, 15:18)
)
exact_phonetic_w <- emWeights(exact_phonetic, cutoff = 0.95)
exact_phonetic_class <- emClassify(exact_phonetic_w, threshold.upper = 0)
```
```{r}
# Extract error measures from each method
err_jarowinkler <- getErrorMeasures(exact_jarowinkler_class)
err_levenshtein <- getErrorMeasures(exact_levenshtein_class)
err_phonetic     <- getErrorMeasures(exact_phonetic_class)

# Create a data frame summarizing key metrics
comparison_table <- data.frame(
  Method = c("Jarowinkler", "Levenshtein", "Phonetic"),
  Accuracy = c(err_jarowinkler$accuracy,
               err_levenshtein$accuracy,
               err_phonetic$accuracy),
  Precision = c(err_jarowinkler$precision,
                err_levenshtein$precision,
                err_phonetic$precision),
  Sensitivity = c(err_jarowinkler$sensitivity,
                  err_levenshtein$sensitivity,
                  err_phonetic$sensitivity),
  Specificity = c(err_jarowinkler$specificity,
                  err_levenshtein$specificity,
                  err_phonetic$specificity)
)

print(comparison_table)
```

The Jaro-Winkler method seems to strike a nice balance. While it only gets about 10% precision (meaning 1 in 10 matches is correct), it manages to catch about 90% of the actual matches (that's the sensitivity score). I'm particularly interested with its accuracy of 99.95%, though this high number is mainly because it's good at identifying non-matches, which make up most of our pairs.

The Levenshtein distance approach is pretty similar but with a trade-off. It's slightly more accurate overall (99.95%), but it misses more true matches, it only catches about 80% of them. This might not be the best choice if we really need to find as many matches as possible.

The Phonetic matching (using Soundex) is interesting - it's the most aggressive in finding matches, catching almost 96% of true matches! However, it pays for this with the lowest precision (only 5.3%). This means it's generating a lot of false positives, it's saying "these records match!" when they actually don't. I imagine this as being overly optimistic about finding matches.


## Approach 2: Blocking on City

```{r}
# 1. Using Jarowinkler
city_block_jarowinkler <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "city",
  strcmp = TRUE,
  strcmpfun = "jarowinkler",
  exclude = c(1:2, 5:13, 15:18)
)
city_block_jarowinkler_w <- emWeights(city_block_jarowinkler, cutoff = 0.95)
city_block_jarowinkler_class <- emClassify(city_block_jarowinkler_w, threshold.upper = 0)
```
```{r}
# 2. Using Levenshtein
city_block_levenshtein <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "city",
  strcmp = TRUE,
  strcmpfun = "levenshtein",
  exclude = c(1:2, 5:13, 15:18)
)
city_block_levenshtein_w <- emWeights(city_block_levenshtein, cutoff = 0.95)
city_block_levenshtein_class <- emClassify(city_block_levenshtein_w, threshold.upper = 0)
```
```{r}
# 3. Using Phonetic Matching (Soundex)
city_block_phonetic <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "city",
  phonetic = TRUE,
  exclude = c(1:2, 5:13, 15:18)
)
city_block_phonetic_w <- emWeights(city_block_phonetic, cutoff = 0.95)
city_block_phonetic_class <- emClassify(city_block_phonetic_w, threshold.upper = 0)
```
```{r}
# Extract error measures
err_city_block_jarowinkler <- getErrorMeasures(city_block_jarowinkler_class)
err_city_block_levenshtein <- getErrorMeasures(city_block_levenshtein_class)
err_city_block_phonetic    <- getErrorMeasures(city_block_phonetic_class)

# Create Comparison Table
comparison_table_city_block <- data.frame(
  Method = c("Jarowinkler", "Levenshtein", "Phonetic"),
  Accuracy = c(err_city_block_jarowinkler$accuracy, err_city_block_levenshtein$accuracy, err_city_block_phonetic$accuracy),
  Precision = c(err_city_block_jarowinkler$precision, err_city_block_levenshtein$precision, err_city_block_phonetic$precision),
  Sensitivity = c(err_city_block_jarowinkler$sensitivity, err_city_block_levenshtein$sensitivity, err_city_block_phonetic$sensitivity),
  Specificity = c(err_city_block_jarowinkler$specificity, err_city_block_levenshtein$specificity, err_city_block_phonetic$specificity)
)

print(comparison_table_city_block)
```


## Approach 3: Blocking on Zip

```{r}
# 1. Using Jarowinkler
zip_block_jarowinkler <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "zip",
  strcmp = TRUE,
  strcmpfun = "jarowinkler",
  exclude = c(1:2, 5:13, 15:18)
)
zip_block_jarowinkler_w <- emWeights(zip_block_jarowinkler, cutoff = 0.95)
zip_block_jarowinkler_class <- emClassify(zip_block_jarowinkler_w, threshold.upper = 0)
```
```{r}
# 2. Using Levenshtein
zip_block_levenshtein <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "zip",
  strcmp = TRUE,
  strcmpfun = "levenshtein",
  exclude = c(1:2, 5:13, 15:18)
)
zip_block_levenshtein_w <- emWeights(zip_block_levenshtein, cutoff = 0.95)
zip_block_levenshtein_class <- emClassify(zip_block_levenshtein_w, threshold.upper = 0)
```
```{r}
# 3. Using Phonetic Matching (Soundex)
zip_block_phonetic <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "zip",
  phonetic = TRUE,
  exclude = c(1:2, 5:13, 15:18)
)
zip_block_phonetic_w <- emWeights(zip_block_phonetic, cutoff = 0.95)
zip_block_phonetic_class <- emClassify(zip_block_phonetic_w, threshold.upper = 0)
```
```{r}
# Extract error measures
err_zip_block_jarowinkler <- getErrorMeasures(zip_block_jarowinkler_class)
err_zip_block_levenshtein <- getErrorMeasures(zip_block_levenshtein_class)
err_zip_block_phonetic    <- getErrorMeasures(zip_block_phonetic_class)

# Create Comparison Table
comparison_table_zip_block <- data.frame(
  Method = c("Jarowinkler", "Levenshtein", "Phonetic"),
  Accuracy = c(err_zip_block_jarowinkler$accuracy, err_zip_block_levenshtein$accuracy, err_zip_block_phonetic$accuracy),
  Precision = c(err_zip_block_jarowinkler$precision, err_zip_block_levenshtein$precision, err_zip_block_phonetic$precision),
  Sensitivity = c(err_zip_block_jarowinkler$sensitivity, err_zip_block_levenshtein$sensitivity, err_zip_block_phonetic$sensitivity),
  Specificity = c(err_zip_block_jarowinkler$specificity, err_zip_block_levenshtein$specificity, err_zip_block_phonetic$specificity)
)

print(comparison_table_zip_block)
```
