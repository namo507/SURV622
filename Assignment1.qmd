---
title: "Assignment 1: Namit Shrivastava"
format: pdf
editor: visual
---

Firstly, I will be installing and loading the RecordLinkage package
```{r warning=FALSE, message=FALSE}
if (!requireNamespace("RecordLinkage", quietly = TRUE)) {
  install.packages('RecordLinkage')
}
library('RecordLinkage', quietly=TRUE)
```

Now given the two csv files, I will be loading and cleaning the data.

```{r}
# Importing datasets
sdfilepath = "surveydata.csv"
adfilepath = "admindata.csv"

# Reading the data
surveydata <- read.csv(sdfilepath, header=TRUE, sep=",", stringsAsFactors = FALSE)
admindata <- read.csv(adfilepath, header=TRUE, sep=",", stringsAsFactors = FALSE)

# Cleaning column names
colnames(surveydata) <- c("matchid","dup","firstname","lastname","maritalstatus",
                         "race","dob","ssn","income","credit_card_num","city",
                         "zip","telephone")
colnames(admindata) <- c("matchid","dup","firstname","lastname","maritalstatus",
                        "race","dob","ssn","income","credit_card_num","city",
                        "zip","telephone")

# Removing empty rows
surveydata <- surveydata[complete.cases(surveydata[,1:2]), ]
admindata <- admindata[complete.cases(admindata[,1:2]), ]

# Creating derived columns
# 1. Full name (first initial + last name)
surveydata$fullname <- paste(substring(surveydata$firstname,1,1), 
                           surveydata$lastname, sep='')
admindata$fullname <- paste(substring(admindata$firstname,1,1), 
                          admindata$lastname, sep='')

# 2. Processing dates
surveydata$dob <- as.Date(surveydata$dob, format="%m/%d/%Y")
admindata$dob <- as.Date(admindata$dob, format="%m/%d/%Y")

# 3. Extracting date components
surveydata$month <- as.numeric(format(surveydata$dob, "%m"))
surveydata$day <- as.numeric(format(surveydata$dob, "%d"))
surveydata$year <- as.numeric(format(surveydata$dob, "%Y"))
admindata$month <- as.numeric(format(admindata$dob, "%m"))
admindata$day <- as.numeric(format(admindata$dob, "%d"))
admindata$year <- as.numeric(format(admindata$dob, "%Y"))

# 4. First three letters of lastname
surveydata$lastthree <- substring(surveydata$lastname,1,3)
admindata$lastthree <- substring(admindata$lastname,1,3)

# Creating identity vectors
identity_survey <- surveydata$matchid
identity_admin <- admindata$matchid

# Verify the data
cat("Data dimensions:\n")
cat("Survey data:", dim(surveydata), "\n")
cat("Admin data:", dim(admindata), "\n")

# Check for NA values in key fields
cat("\nMissing values in key fields:\n")
cat("Survey DOB NAs:", sum(is.na(surveydata$dob)), "\n")
cat("Admin DOB NAs:", sum(is.na(admindata$dob)), "\n")
```

Now let me analyse and explain the data in layman terms.

So I have 2 datasets, a survey dataset with 3,000 records and a larger administrative dataset with 13,551 records. Both datasets now have 18 columns each, which includes our original fields plus the new ones that I created (like the full name combining first initial and last name, and the separated date components).

What's interesting, and potentially concerning, is that I have some missing dates of birth: 11 missing in the survey data and 49 missing in the administrative data. This could impact my matching process since date of birth is often a key field for linking records. I will need to keep this in mind when I move forward with record linkage, as these records might be harder to match confidently.


## Approach 1: Exact Matching (No Blocking)
```{r}
# 1. Using Jarowinkler
exact_jarowinkler <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = NULL,
  strcmp = TRUE,
  strcmpfun = "jarowinkler",
  exclude = c(1:2, 5:13, 15:18)
)
exact_jarowinkler_w <- emWeights(exact_jarowinkler, cutoff = 0.95)
exact_jarowinkler_class <- emClassify(exact_jarowinkler_w, threshold.upper = 0)
```
```{r}
# 2. Using Levenshtein
exact_levenshtein <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = NULL,
  strcmp = TRUE,
  strcmpfun = "levenshtein",
  exclude = c(1:2, 5:13, 15:18)
)
exact_levenshtein_w <- emWeights(exact_levenshtein, cutoff = 0.95)
exact_levenshtein_class <- emClassify(exact_levenshtein_w, threshold.upper = 0)
```
```{r}
# 3. Using Phonetic Matching (Soundex)
exact_phonetic <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = NULL,
  phonetic = TRUE,
  exclude = c(1:2, 5:13, 15:18)
)
exact_phonetic_w <- emWeights(exact_phonetic, cutoff = 0.95)
exact_phonetic_class <- emClassify(exact_phonetic_w, threshold.upper = 0)
```
```{r}
# Extract error measures from each method
err_jarowinkler <- getErrorMeasures(exact_jarowinkler_class)
err_levenshtein <- getErrorMeasures(exact_levenshtein_class)
err_phonetic     <- getErrorMeasures(exact_phonetic_class)

# Create a data frame summarizing key metrics
comparison_table <- data.frame(
  Method = c("Jarowinkler", "Levenshtein", "Phonetic"),
  Accuracy = c(err_jarowinkler$accuracy,
               err_levenshtein$accuracy,
               err_phonetic$accuracy),
  Precision = c(err_jarowinkler$precision,
                err_levenshtein$precision,
                err_phonetic$precision),
  Sensitivity = c(err_jarowinkler$sensitivity,
                  err_levenshtein$sensitivity,
                  err_phonetic$sensitivity),
  Specificity = c(err_jarowinkler$specificity,
                  err_levenshtein$specificity,
                  err_phonetic$specificity)
)

print(comparison_table)
```

* Jaro-Winkler Method
The Jaro-Winkler method seems to strike a nice balance. While it only gets about 10% precision (meaning 1 in 10 matches is correct), it manages to catch about 90% of the actual matches (that's the sensitivity score). I'm particularly interested with its accuracy of 99.95%, though this high number is mainly because it's good at identifying non-matches, which make up most of our pairs.

* Levenshtein Distance
The Levenshtein distance approach is pretty similar but with a trade-off. It's slightly more accurate overall (99.95%), but it misses more true matches, it only catches about 80% of them. This might not be the best choice if we really need to find as many matches as possible.

* Phonetic Matching
The Phonetic matching (using Soundex) is interesting, it's the most aggressive in finding matches, catching almost 96% of true matches! However, it pays for this with the lowest precision (only 5.3%). This means it's generating a lot of false positives, it's saying "these records match!" when they actually don't. I imagine this as being overly optimistic about finding matches.


## Approach 2: Blocking on City

```{r}
# 1. Using Jarowinkler
city_block_jarowinkler <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "city",
  strcmp = TRUE,
  strcmpfun = "jarowinkler",
  exclude = c(1:2, 5:13, 15:18)
)
city_block_jarowinkler_w <- emWeights(city_block_jarowinkler, cutoff = 0.95)
city_block_jarowinkler_class <- emClassify(city_block_jarowinkler_w, threshold.upper = 0)
```
```{r}
# 2. Using Levenshtein
city_block_levenshtein <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "city",
  strcmp = TRUE,
  strcmpfun = "levenshtein",
  exclude = c(1:2, 5:13, 15:18)
)
city_block_levenshtein_w <- emWeights(city_block_levenshtein, cutoff = 0.95)
city_block_levenshtein_class <- emClassify(city_block_levenshtein_w, threshold.upper = 0)
```
```{r}
# 3. Using Phonetic Matching (Soundex)
city_block_phonetic <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "city",
  phonetic = TRUE,
  exclude = c(1:2, 5:13, 15:18)
)
city_block_phonetic_w <- emWeights(city_block_phonetic, cutoff = 0.95)
city_block_phonetic_class <- emClassify(city_block_phonetic_w, threshold.upper = 0)
```
```{r}
# Extract error measures
err_city_block_jarowinkler <- getErrorMeasures(city_block_jarowinkler_class)
err_city_block_levenshtein <- getErrorMeasures(city_block_levenshtein_class)
err_city_block_phonetic    <- getErrorMeasures(city_block_phonetic_class)

# Create Comparison Table
comparison_table_city_block <- data.frame(
  Method = c("Jarowinkler", "Levenshtein", "Phonetic"),
  Accuracy = c(err_city_block_jarowinkler$accuracy, err_city_block_levenshtein$accuracy, err_city_block_phonetic$accuracy),
  Precision = c(err_city_block_jarowinkler$precision, err_city_block_levenshtein$precision, err_city_block_phonetic$precision),
  Sensitivity = c(err_city_block_jarowinkler$sensitivity, err_city_block_levenshtein$sensitivity, err_city_block_phonetic$sensitivity),
  Specificity = c(err_city_block_jarowinkler$specificity, err_city_block_levenshtein$specificity, err_city_block_phonetic$specificity)
)

print(comparison_table_city_block)
```


Now when I used city as a blocking variable (meaning I only compared records within the same city), I saw some really interesting improvements over the non-blocked approach from before:

* Jaro-Winkler Method
I'm quite impressed with how the Jaro-Winkler method performed here. Its precision jumped up to about 52% - that's a huge improvement from the previous 10%! This means when using city blocking, about half of our predicted matches are actually correct matches. It still maintains that strong 90% sensitivity, meaning it's catching most of the true matches. This is looking like a really solid approach.

* Levenshtein Distance
The Levenshtein method shows similar patterns to Jaro-Winkler, with about 51% precision. However, it's still missing more matches than Jaro-Winkler (only 80% sensitivity). While the precision improvement is great, that lower sensitivity could be a concern if we need to catch as many true matches as possible.

* Phonetic Matching
The phonetic matching is still our most aggressive matcher - it finds about 96% of true matches (highest sensitivity), but its precision is only around 27%. While this is better than its non-blocked version (which was at 5%), it's still generating quite a few false positives.

Overall I would say the most exciting thing I'm seeing is how city blocking dramatically improved our precision across all methods while maintaining very high accuracy (99.9%+). This tells me that restricting comparisons to records within the same city is a really effective strategy, it's cutting out a lot of the noise that was causing false matches in our previous approach.

If I had to pick a winner here, I'd go with the Jaro-Winkler method with city blocking. It gives us the best balance of precision and sensitivity, and those numbers look much more practical for real-world use than our non-blocked results.


## Approach 3: Blocking on Zip

```{r}
# 1. Using Jarowinkler
zip_block_jarowinkler <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "zip",
  strcmp = TRUE,
  strcmpfun = "jarowinkler",
  exclude = c(1:2, 5:13, 15:18)
)
zip_block_jarowinkler_w <- emWeights(zip_block_jarowinkler, cutoff = 0.95)
zip_block_jarowinkler_class <- emClassify(zip_block_jarowinkler_w, threshold.upper = 0)
```
```{r}
# 2. Using Levenshtein
zip_block_levenshtein <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "zip",
  strcmp = TRUE,
  strcmpfun = "levenshtein",
  exclude = c(1:2, 5:13, 15:18)
)
zip_block_levenshtein_w <- emWeights(zip_block_levenshtein, cutoff = 0.95)
zip_block_levenshtein_class <- emClassify(zip_block_levenshtein_w, threshold.upper = 0)
```
```{r}
# 3. Using Phonetic Matching (Soundex)
zip_block_phonetic <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "zip",
  phonetic = TRUE,
  exclude = c(1:2, 5:13, 15:18)
)
zip_block_phonetic_w <- emWeights(zip_block_phonetic, cutoff = 0.95)
zip_block_phonetic_class <- emClassify(zip_block_phonetic_w, threshold.upper = 0)
```
```{r}
# Extract error measures
err_zip_block_jarowinkler <- getErrorMeasures(zip_block_jarowinkler_class)
err_zip_block_levenshtein <- getErrorMeasures(zip_block_levenshtein_class)
err_zip_block_phonetic    <- getErrorMeasures(zip_block_phonetic_class)

# Create Comparison Table
comparison_table_zip_block <- data.frame(
  Method = c("Jarowinkler", "Levenshtein", "Phonetic"),
  Accuracy = c(err_zip_block_jarowinkler$accuracy, err_zip_block_levenshtein$accuracy, err_zip_block_phonetic$accuracy),
  Precision = c(err_zip_block_jarowinkler$precision, err_zip_block_levenshtein$precision, err_zip_block_phonetic$precision),
  Sensitivity = c(err_zip_block_jarowinkler$sensitivity, err_zip_block_levenshtein$sensitivity, err_zip_block_phonetic$sensitivity),
  Specificity = c(err_zip_block_jarowinkler$specificity, err_zip_block_levenshtein$specificity, err_zip_block_phonetic$specificity)
)

print(comparison_table_zip_block)
```

Now analysing with ZIP Blocking:

* Jaro-Winkler Method 
I'm absolutely amazed by how well the Jaro-Winkler method performed with ZIP code blocking. The precision skyrocketed to about 95%. This means when the method says "these records match," it's right 95 out of 100 times. Even better, it still maintains that strong 90% sensitivity, meaning it's catching most of the true matches. This is a dramatic improvement over both the no-blocking approach and even the city-blocking method.

* Levenshtein Distance
The Levenshtein approach shows similarly impressive precision (about 95%), nearly matching Jaro-Winkler. However, it's still showing that same limitation we saw before, it's only catching about 80% of the true matches. While the precision is fantastic, missing 20% of true matches might be too big a trade-off in some situations.

* Phonetic Matching 
The phonetic matching seems to have struggled with ZIP blocking. While it still finds about 96% of true matches (highest sensitivity), its precision dropped dramatically to about 5%. This is surprisingly lower than what we saw with city blocking, suggesting that ZIP codes might actually be too restrictive for phonetic matching.


So, using ZIP codes for blocking has given me the best precision yet, especially with the Jaro-Winkler method. The accuracy remains extremely high across all methods (99.8%+), but the real story here is how ZIP blocking helped Jaro-Winkler and Levenshtein methods achieve such high precision without sacrificing too much sensitivity.

If I had to pick a winner based on these results, I'd definitely go with the Jaro-Winkler method with ZIP blocking. Getting 95% precision while still catching 90% of true matches is a fantastic balance that would work well in most real-world applications.


## Approach 4: Blocking on Lastname

```{r}
# 1. Using Jarowinkler
lastname_block_jarowinkler <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "lastname",
  strcmp = TRUE,
  strcmpfun = "jarowinkler",
  exclude = c(1:2, 5:13, 15:18)
)
lastname_block_jarowinkler_w <- emWeights(lastname_block_jarowinkler, cutoff = 0.95)
lastname_block_jarowinkler_class <- emClassify(lastname_block_jarowinkler_w, threshold.upper = 0)
```
```{r}
# 2. Using Levenshtein
lastname_block_levenshtein <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "lastname",
  strcmp = TRUE,
  strcmpfun = "levenshtein",
  exclude = c(1:2, 5:13, 15:18)
)
lastname_block_levenshtein_w <- emWeights(lastname_block_levenshtein, cutoff = 0.95)
lastname_block_levenshtein_class <- emClassify(lastname_block_levenshtein_w, threshold.upper = 0)
```
```{r}
# 3. Using Phonetic Matching (Soundex)
lastname_block_phonetic <- RLBigDataLinkage(
  dataset1 = surveydata,
  dataset2 = admindata,
  identity1 = identity_survey,
  identity2 = identity_admin,
  blockfld = "lastname",
  phonetic = TRUE,
  exclude = c(1:2, 5:13, 15:18)
)
lastname_block_phonetic_w <- emWeights(lastname_block_phonetic, cutoff = 0.95)
lastname_block_phonetic_class <- emClassify(lastname_block_phonetic_w, threshold.upper = 0)
```
```{r}
# Extract error measures
err_lastname_block_jarowinkler <- getErrorMeasures(lastname_block_jarowinkler_class)
err_lastname_block_levenshtein <- getErrorMeasures(lastname_block_levenshtein_class)
err_lastname_block_phonetic    <- getErrorMeasures(lastname_block_phonetic_class)

# Create Comparison Table
comparison_table_lastname_block <- data.frame(
  Method = c("Jarowinkler", "Levenshtein", "Phonetic"),
  Accuracy = c(err_lastname_block_jarowinkler$accuracy, err_lastname_block_levenshtein$accuracy, err_lastname_block_phonetic$accuracy),
  Precision = c(err_lastname_block_jarowinkler$precision, err_lastname_block_levenshtein$precision, err_lastname_block_phonetic$precision),
  Sensitivity = c(err_lastname_block_jarowinkler$sensitivity, err_lastname_block_levenshtein$sensitivity, err_lastname_block_phonetic$sensitivity),
  Specificity = c(err_lastname_block_jarowinkler$specificity, err_lastname_block_levenshtein$specificity, err_lastname_block_phonetic$specificity)
)

print(comparison_table_lastname_block)
```